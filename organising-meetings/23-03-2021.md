# 23rd March 2021
Nina and Natalie.

Meeting to discuss ways forward with this piece and where to go with it next. 

## What are the aims of the piece?
- Bringing ethical considerations to parts of research which are still conceptual, or in fields where ethical review isn't standard. Just because the research is not on human subjects, does not mean it will not affect human or living subjects. 
- Recognising that there are lots of people with expertise - encourage collaboration. How to set up these collaborations. (Comp Sci/Sociology for example)
- Providing a framework and case studies of how this could be applied in practice. 

The idea is not to discourage research or innovation, but that if you realise something is possible, you can label it at that point and people can't claim ignorance.

### Thoughts
We discussed the **consequence scanning** concept. Our idea we think is broader than this, which mostly seems aimed at commercial applications. It also doesn't necessarily get around the issue of people within hierarchies just listening to the most senior person.

We talked about potential hazards of the hazard labels (there's a section in the main doc on this now).
- Using them for evil by pointing out potential for misuse of technology. 
- Potential for funders to use them as a reason not to fund research that has potential negative consequences. 

Data Hazard labels 
- We want these to be more about directions than 'amount' of consequence. 
- Nat has some examples she has already thought of. Max of 12 to begin with seems sensible. 
- Started a list of potentials on the [GitHub project board](https://github.com/very-good-science/data-hazards/projects/1). 

### How would this 'framework' work?
We liked the idea of including this as part of a pre-registration format. This would mean ethical considerations are subject to peer review like the rest of the research proposal. It also brings ethics to the fore in projects which wouldn't usually go through ethical review. 

We want to involve data scientists and people from the humanities. It doesn't have to be super involved process though. 

Options include: 
- Work gets sent to humanities people for review and the labels they give are those the piece gets.
- Collaborative decision by both the researcher and reviewers. 
- Both reviewer and research think of potential negative consequences and then compare notes. 

Ideally the approach will result in researchers thinking more carefully about the ethics of their work, which is why we like the idea of involving the researcher in some way. Otherwise it becomes something that is 'done to' rather than 'done with'.  

### People We Want To Talk To
- People from funding bodies - James Heatherington?
- Digital Futures Institute (as collaborators?)
- Publishers - including Tessa, who is thinking of ethics review.
- Who is leading the ethics training for the new CDT ?

### Criticisms of this approach
- It could just be another box ticking exercise.
- Lots of people are likely to not want to engage with it. 
- It requires more unpaid reviewing time (etc) that academia is particularly known for. This might be particularly worth thinking about in terms of who would do this reviewing - people from disadvantaged backgrounds are best places to recognise impacts on others in similar contexts, but are least likely to have the time and energy to do this type of reviewing. 

### Next steps
Writing some introductory paragraphs, that can also be shared with collaborators to explain the idea?
- Paragraph about why this kind of thing is necessary in the first place (looking at CDEI review, the Turing social care review). Ethics committees don't really review for comp sci/maths/engineering. 
- Paragraph about where this sits in the life cycle of research. [Patterns Maturity Lifecycle](https://www.cell.com/patterns/dsml)


- Come up with a idea of a small number of labels. (Keeping it small to begin with) - see [Trello project board](https://github.com/very-good-science/data-hazards/projects/1). 

- Come up with a rough idea of how the process would work so we can bring it to people to discuss collaborating with them on it. 